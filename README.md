# SparseOps Backend: Quasiâ€‘Dense Sparse Matrix Kernels

This repository implements a custom CPU backend for very efficient sparse **matrixâ€“vector** and **matrixâ€“matrix** multiplications.  It achieves this by:

1. **Encoding** a sparse matrix into a â€œquasiâ€‘denseâ€ format that packs each rowâ€™s nonâ€‘zero entries into a fixedâ€‘width buffer.  
2. Exposing two highlyâ€‘optimized kernelsâ€”one for **matâ€‘vec** and one for **matâ€‘mul**â€”that operate directly on this format, leveraging  
   - runtime detection of AVXâ€‘512 / AVX2,  
   - OpenMP for parallelism,  
   - 64â€‘byte alignment for maximal throughput.  
3. Wrapping everything in a **pybind11**â€‘based Python API, so you can do
   ```python
   Q    = encode(dense_matrix)          # build the QuasiDense handle
   y    = matvec(Q, x, bias)            # sparse matrixâ€“vector multiply
   Y    = matmul(Q, X, bias)            # sparse matrixâ€“matrix multiply
    ````

4. Providing both **unit tests** (via pytest) for correctness and **benchmark scripts** for performance exploration.

---

## ğŸ“‚ Repository Structure

```
.
â”œâ”€â”€ include/
â”‚   â”œâ”€â”€ aligned_buffer.hpp            â€” 64â€‘byteâ€‘aligned float buffer wrapper
â”‚   â”œâ”€â”€ quasi_dense_encoder.hpp       â€” QuasiDense struct + encode/decode APIs
â”‚   â”œâ”€â”€ bilinear_diagonal_matvec.hpp  â€” declaration of quasi_dense_matvec
â”‚   â””â”€â”€ bilinear_diagonal_matmul.hpp  â€” declaration of quasi_dense_matmul
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ aligned_buffer.cpp            â€” (none; headerâ€‘only)
â”‚   â”œâ”€â”€ quasi_dense_encoder.cpp       â€” implementation of convert/decode
â”‚   â”œâ”€â”€ bilinear_diagonal_matvec.cpp  â€” vector kernel
â”‚   â”œâ”€â”€ bilinear_diagonal_matmul.cpp  â€” matrix kernel
â”‚   â””â”€â”€ bindings.cpp                  â€” pybind11 glue
â”‚
â”œâ”€â”€ python/
â”‚   â””â”€â”€ cpp_backend.py                â€” thin Python wrapper over the C++ module
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_matvec.py                â€” endâ€‘toâ€‘end matâ€‘vec benchmark/demo
â”‚   â””â”€â”€ test_matmul.py                â€” endâ€‘toâ€‘end matâ€‘mul benchmark/demo
â”‚
â”œâ”€â”€ tests/unit/
â”‚   â”œâ”€â”€ test_quasi_encoder.py         â€” correctness of encode/decode
â”‚   â”œâ”€â”€ test_matvec.py                â€” correctness of matâ€‘vec kernel
â”‚   â””â”€â”€ test_matmul.py                â€” correctness of matâ€‘mul kernel
â”‚
â”œâ”€â”€ CMakeLists.txt                    â€” build instructions
â”œâ”€â”€ rebuild.sh                        â€” helper script
â””â”€â”€ README.md                         â€” this document
```

---

## ğŸ”§ Quasiâ€‘Dense Format

### `include/quasi_dense_encoder.hpp`â€¯â†’â€¯`src/quasi_dense_encoder.cpp`

```cpp
struct QuasiDense {
    uint32_t m;    // # rows
    uint32_t n;    // # cols (original)
    uint32_t r;    // max nonâ€‘zeros in any row

    AlignedBuffer     Wd;      // [m Ã— r] packed nonâ€‘zero values
    std::vector<uint32_t> idx; // [m Ã— r] column indices
    AlignedBuffer     Xt;      // [m Ã— r] scratch buffer for gathers
    std::vector<uint32_t> nnz;     // actual nnz per row
    std::vector<uint32_t> rev_off; // CSRâ€‘style row offsets for decode
    std::vector<uint32_t> rev_pos; // flattened positions for decode
};
```

1. **Encoding** (`convert_to_quasi_dense`):

   * **Scan** each row of the original dense matrixÂ `W` to **count** its nonâ€‘zeros â†’â€¯`rowCounts[i]`.
   * **Find** `r = max(rowCounts)`.
   * **Allocate** a `QuasiDense Q(m,n,r)`.
   * **Zeroâ€‘initialize** `Q.Wd` then **pack** every nonâ€‘zero `v` at `(i,j)` into `Q.Wd.ptr[i*r + pos]` and `Q.idx[i*r + pos] = j`.
   * **Build** reverse offsets `rev_off` and flattened positions `rev_pos` so you can **scatter** back if desired.
2. **Decoding** (`decode_from_quasi_dense`):

   * Zero out an `mÃ—n` output buffer.
   * For each rowâ€¯`i`, for `j` in `[0..nnz[i])` scatter `Q.Wd.ptr[i*r + j]` back to its original column index.

---

## ğŸš€ Sparse Matrixâ€“Vector Multiply

### API

```cpp
void quasi_dense_matvec(
    const QuasiDense &Q,
    const float*      x,     // length = Q.n
    const float*      bias,  // length = Q.m (or nullptr to zeroâ€init)
    float*            y      // length = Q.m
);
```

### Key points (see `src/bilinear_diagonal_matvec.cpp`)

1. **Output Init**

   * If `bias` is nonâ€null, `memcpy(y, bias, â€¦)`, else `fill(y, 0)`.
2. **Threading**

   * Read `OMP_NUM_THREADS`; fall back to `omp_get_max_threads()`.
   * `#pragma omp parallel for` over theâ€¯`m` rows.
3. **SIMD**

   * At runtime call `supports_avx512()` â†’ if available, use \_mm512 intrinsics; otherwise fall back to AVX2/\_mm256 or plain loops.
   * **Gather**: load the `r` elements of `x` into the aligned scratch buffer `Q.Xt.ptr + i*r`.
   * **Dot**: FMAâ€accelerated fused multiplyâ€adds over `Q.Wd` and the gathered `Q.Xt` row.
   * **Horizontal reduction** to collapse the SIMD register to a scalar, then `y[i] += acc`.

---

## ğŸš€ Sparse Matrixâ€“Matrix Multiply

### API

```cpp
void quasi_dense_matmul(
    const QuasiDense &Q,
    const float*      X,     // shape = [Q.n Ã— C]
    uint32_t          C,
    const float*      bias,  // length = Q.m
    float*            Y      // out buffer shape = [Q.m Ã— C]
);
```

### Highâ€‘Level Algorithm (in `src/bilinear_diagonal_matmul.cpp`)

```text
for each row i in 0..m-1:
    yrow = Y + i        // pointer to row i storage
    yrow[*] â† bias[i]   // broadcast bias to all C columns

    // For each packed nonâ€‘zero in row i:
    for t in 0..r-1:  
        w = Q.Wd.ptr[i*r + t]       // value
        col = Q.idx[i*r + t]        // original column
        xrow = X + col*C            // pointer to that column in X

        // vectorized:  Y_row[0..C) += w * X[col,0..C)
        // tailâ€‘handle for C % VLEN
```

* Parallelized over `i` with OpenMP.
* Uses AVX2 intrinsics (`_mm256_fmadd_ps`) for the inner loop.

---

## ğŸ Python Bindings

All C++ types/functions are exposed by **pybind11** in `src/bindings.cpp` as the module **`sparseops_backend`**:

* **Classes & Handles**

  ```python
  Q = sparseops_backend.convert_to_quasi_dense(np_matrix)
  ```
* **Methods**

  ```python
  Y = sparseops_backend.decode_from_quasi_dense(Q)
  y = sparseops_backend.bilinear_diagonal_matvec(Q, x, bias)
  Y = sparseops_backend.bilinear_diagonal_matmul(Q, X, bias)
  ```
* **Properties** on `QuasiDense`:

  * `.m, .n, .r` (dimensions)
  * `.Wd` â†’ NumPy view of the packed values (shapeâ€¯`[m, r]`)
  * `.idx` â†’ NumPy view of the packed columnâ€indices (shapeâ€¯`[m, r]`)
  * `.Xt` â†’ the scratch buffer (usually you donâ€™t need this directly)
* A thin helper wrapper in `python/cpp_backend.py` reâ€‘exports these as `encode`, `matvec`, and `matmul` for convenience.

---

## ğŸ” Usage Examples

### Vector Multiply

```python
import numpy as np
from python.cpp_backend import encode, matvec

W = np.random.randn(512, 256).astype(np.float32)
W[W < 0.8] = 0.0                          # sparsify
Q = encode(W)                            # build QuasiDense
x = np.random.randn(256).astype(np.float32)
bias = np.random.randn(512).astype(np.float32)

y = matvec(Q, x, bias)                   # shape = (512,)
# y  ==  W @ x + bias
```

### Matrix Multiply

```python
import numpy as np
from python.cpp_backend import encode, matmul

W = np.random.randn(1024, 512).astype(np.float32)
W[W < 0.9] = 0.0
Q = encode(W)

X = np.random.randn(512, 10).astype(np.float32)
bias = np.random.randn(1024).astype(np.float32)

Y = matmul(Q, X, bias)                   # shape = (1024, 10)
# Y  ==  W @ X  +  bias[:,None]
```

The scripts under `tests/` (e.g. `test_matvec.py`, `test_matmul.py`) show how to integrate this into a benchmark loop, comparing against PyTorch, NumPy, and SciPy.

---

## âœ… Correctness & Benchmarks

* **Unit tests** in `tests/unit/` validate:

  * Roundâ€‘trip **encodeâ€¯â†”â€¯decode**
  * **matvec** correctness against a dense reference
  * **matmul** correctness across various sizes & sparsities
* **Benchmark scripts** in `tests/` measure the throughput over many runs, illustrating the performance gains on modern CPUs when using AVX and multiâ€‘threading.

---

## âš™ï¸ Building

1. Install prerequisites:

   * C++17 compiler with OpenMP & AVX2/AVX512 support
   * [pybind11](https://github.com/pybind/pybind11)
   * PythonÂ 3, NumPy

2. From the repo root:

   ```bash
   mkdir build
   cmake --build build -j
   # this produces `lib(sparseops_backend).so` that Python can import
   ```

3. (Optional) Run unit tests:

   ```bash
   pytest tests/unit
   ```

---

With this setup, you get a flexible, highâ€‘performance sparse CPU backend that can slot into your NumPy/PyTorch workflows with minimal boilerplate. Enjoy!
